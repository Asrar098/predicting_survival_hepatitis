{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Basic Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load data into pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hepatitis_data = pd.read_csv(\"dataset_55_hepatitis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction algorithm**  \n",
    "\n",
    "One of the main decisions to make when performing machine learning is choosing the appropriate algorithm that fits the current problem we are dealing with.\n",
    "**Supervised learning** refers to the task of inferring a function from a labeled training dataset. We fit the model to the labeled training set with the main goal of finding the optimal parameters that will predict unknown labels of new examples included in the test dataset. There are two main types of supervised learning: regression, in which we want to predict a label that is a real number, and classification, in which we want to predict a categorical label.\n",
    "In our case, we have a labeled dataset and we want to use a classification algorithm to find the label in the categorical values: 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find many classification supervised learning algorithms, some simple but efficient, such as linear classifier or logistic regression, and another ones more complex but powerful such as decision trees and k-means.  \n",
    "In this case, we will choose **Random Forest** algorithm. Random forest is one of the most used machine learning algorithm due to the fact that it is very simple, flexible and easy to use but produces reliable results.\n",
    "So we will load the packages from scikit-learn that we need to perform Random Forest and also to evaluate afterwards the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {'no': 0,\n",
    "               'yes': 1,\n",
    "               'DIE': 0,\n",
    "               'LIVE': 1,\n",
    "               '?': np.nan,\n",
    "               'female': 0,\n",
    "               'male': 1}\n",
    "\n",
    "hepatitis_data.replace(replacements, inplace = True)\n",
    "hepatitis_data = hepatitis_data.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the EDA, we dropped all `NaN` values. Here, we need to evaluate what is the best method to handle them.  \n",
    "There are several ways to deal with missing data but none of them is perfect. The first step is to understand why data went missing. In our case, we can guess that the values missing in the categorical variables could be due to the absence of the feature that instead of being imputed as 'no' was left blank or that it was not tested. In contrast, missing values in continuous variables could be explained by the lack of biochemical studies performed in that particular patient.  \n",
    "\n",
    "In the case of the categorical variables, we could be in the presence of **Missing at Random** value (The fact that the value is missing has nothing to do with the hypothetical value) or **Missing not at Random** value (The missing value depends on the hypothetical value). If it was the first one, we could drop the `NaN` value safely, while in the last case it would not be safe to drop it because this missing value tell us something about the hypothetical value. Assuming the risks, we will treat the missing values as missing at random.  \n",
    "\n",
    "On the other hand, the missing data in the continuos variables could be explained as **Missing at Random** and could safely be dropped. Because as we can see below, the `NaN` values are high in some of the variables (e.g PROTIME), we could use the Pairwise deletion to be sure be don't end up with too few cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                 0\n",
       "SEX                 0\n",
       "STEROID             1\n",
       "ANTIVIRALS          0\n",
       "FATIGUE             1\n",
       "MALAISE             1\n",
       "ANOREXIA            1\n",
       "LIVER_BIG          10\n",
       "LIVER_FIRM         11\n",
       "SPLEEN_PALPABLE     5\n",
       "SPIDERS             5\n",
       "ASCITES             5\n",
       "VARICES             5\n",
       "BILIRUBIN           6\n",
       "ALK_PHOSPHATE      29\n",
       "SGOT                4\n",
       "ALBUMIN            16\n",
       "PROTIME            67\n",
       "HISTOLOGY           0\n",
       "Class               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hepatitis_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Test datasets**\n",
    "\n",
    "In order to train and test our model, we need to split our dataset into to subdatasets, the training and the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
